{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de328150",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854ad010",
   "metadata": {},
   "source": [
    "## Q1. What is the role of feature selection in anomaly detection?\n",
    "Feature selection in anomaly detection helps identify the most relevant features that contribute to detecting anomalies, reducing noise and irrelevant information. It improves the accuracy of anomaly detection models, reduces overfitting, enhances computational efficiency, and helps in better understanding the data by focusing on critical attributes that differentiate normal points from anomalies.\n",
    "\n",
    " ## Q2. What are some common evaluation metrics for anomaly detection algorithms and how are they computed?\n",
    "Common evaluation metrics include:\n",
    "\n",
    "Precision: Measures the proportion of true anomalies correctly identified out of all instances classified as anomalies.\n",
    "Precision\n",
    "=\n",
    "True Positives\n",
    "True Positives\n",
    "+\n",
    "False Positives\n",
    "Precision= \n",
    "True Positives+False Positives\n",
    "True Positives\n",
    "​\n",
    " \n",
    "Recall (Sensitivity): Measures the proportion of actual anomalies correctly identified.\n",
    "Recall\n",
    "=\n",
    "True Positives\n",
    "True Positives\n",
    "+\n",
    "False Negatives\n",
    "Recall= \n",
    "True Positives+False Negatives\n",
    "True Positives\n",
    "​\n",
    " \n",
    "F1-Score: Harmonic mean of precision and recall, balancing both metrics.\n",
    "F1-Score\n",
    "=\n",
    "2\n",
    "⋅\n",
    "Precision\n",
    "⋅\n",
    "Recall\n",
    "Precision\n",
    "+\n",
    "Recall\n",
    "F1-Score=2⋅ \n",
    "Precision+Recall\n",
    "Precision⋅Recall\n",
    "​\n",
    " \n",
    "AUC-ROC (Area Under the Curve - Receiver Operating Characteristic): Measures the trade-off between true positive rate and false positive rate across different thresholds.\n",
    "## Q3. What is DBSCAN and how does it work for clustering?\n",
    "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a clustering algorithm that groups points that are closely packed together based on their density. It identifies clusters of arbitrary shape by labeling points as either core, border, or noise points:\n",
    "\n",
    "Core points: Points with at least a minimum number of neighbors within a specified radius (epsilon).\n",
    "Border points: Points that are not core points but are within the neighborhood of a core point.\n",
    "Noise points: Points that are neither core nor border points.\n",
    "## Q4. How does the epsilon parameter affect the performance of DBSCAN in detecting anomalies?\n",
    "The epsilon parameter (ε) in DBSCAN defines the radius within which points are considered neighbors. A smaller epsilon may result in too many small clusters or isolated points (false positives as anomalies), while a larger epsilon may include too many points in the same cluster, missing actual anomalies (false negatives). Proper tuning of ε is essential for balancing the detection of true anomalies and noise.\n",
    "\n",
    "## Q5. What are the differences between the core, border, and noise points in DBSCAN, and how do they relate to anomaly detection?\n",
    "Core points: Have enough neighbors within epsilon to form a dense region. They form the center of clusters.\n",
    "Border points: Lie within the neighborhood of a core point but don’t have enough neighbors themselves to be core points.\n",
    "Noise points: Do not belong to any cluster and are considered anomalies. Noise points are crucial in anomaly detection as they represent outliers or isolated points that don’t fit into any cluster.\n",
    "## Q6. How does DBSCAN detect anomalies and what are the key parameters involved in the process?\n",
    "DBSCAN detects anomalies by identifying points that are not assigned to any cluster (noise points). The key parameters involved are:\n",
    "\n",
    "Epsilon (ε): Defines the neighborhood radius around each point.\n",
    "MinPts: Minimum number of points required within ε to form a core point. Points that do not meet these criteria are considered noise and are flagged as anomalies.\n",
    "## Q7. What is the make_circles package in scikit-learn used for?\n",
    "The make_circles function in scikit-learn is used to generate synthetic 2D datasets with circular patterns. It’s often used to test clustering and classification algorithms on non-linear, circular data. It creates a set of points arranged in concentric circles, allowing for testing how well algorithms handle non-linearly separable data.\n",
    "\n",
    "## Q8. What are local outliers and global outliers, and how do they differ from each other?\n",
    "Local outliers are data points that are outliers within a small, localized region of the data. They may appear normal globally but deviate significantly within their local neighborhood.\n",
    "Global outliers are data points that are outliers in the overall dataset and differ significantly from the majority of the data regardless of the neighborhood.\n",
    "## Q9. How can local outliers be detected using the Local Outlier Factor (LOF) algorithm?\n",
    "The Local Outlier Factor (LOF) algorithm detects local outliers by comparing the local density of a data point to that of its neighbors. A point is considered a local outlier if its density is significantly lower than the densities of its neighboring points. The LOF score quantifies how isolated a point is compared to its surroundings.\n",
    "\n",
    "## Q10. How can global outliers be detected using the Isolation Forest algorithm?\n",
    "The Isolation Forest algorithm detects global outliers by randomly partitioning the data and isolating individual points. Anomalous points tend to be isolated faster, resulting in shorter path lengths in the isolation trees. The anomaly score is based on the average path length; globally isolated points will have high anomaly scores.\n",
    "\n",
    "## Q11. What are some real-world applications where local outlier detection is more appropriate than global outlier detection, and vice versa?\n",
    "Local outlier detection is more appropriate in scenarios where anomalies are context-dependent, such as fraud detection in specific customer segments or sensor fault detection in localized environments.\n",
    "Global outlier detection is more appropriate when the anomalies are rare events in the overall dataset, such as identifying network intrusions, system failures, or major fraud cases affecting the entire system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daf54ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
